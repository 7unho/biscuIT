{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HetokZ84DT0e"
      },
      "source": [
        "## "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "tonmKxNBC6s7"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import urllib.request\n",
        "from collections import Counter\n",
        "from typing import List"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "2ixX19lmm8zs"
      },
      "outputs": [],
      "source": [
        "# TextRank\n",
        "from gensim.summarization.summarizer import summarize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "hkce62xgzA5c"
      },
      "outputs": [],
      "source": [
        "# kiwi: Tokenizer\n",
        "from kiwipiepy import Kiwi\n",
        "# keyBert\n",
        "from keybert import KeyBERT\n",
        "from transformers import BertModel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "tT4-deliwcQM"
      },
      "outputs": [],
      "source": [
        "from tqdm.notebook import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U0LF5cA5zCmb"
      },
      "source": [
        "## data 전처리"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ogEaZdn7KKkM"
      },
      "source": [
        "### Tokenize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "mWo2YUCyKScN"
      },
      "outputs": [],
      "source": [
        "kiwi = Kiwi()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "1ZPxj9iuKSfX"
      },
      "outputs": [],
      "source": [
        "# 명사 추출 함수\n",
        "def noun_extractor(text):\n",
        "    results = []\n",
        "    result = kiwi.analyze(text)\n",
        "    # print(result)\n",
        "    for token, pos, _, _ in result[0][0]:\n",
        "        if len(token) != 1 and pos.startswith('N') or pos.startswith('SL'):\n",
        "            results.append(token)\n",
        "    return results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pLHwJBTIyx9_"
      },
      "source": [
        "## keyword 추출"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "t-uzs8GQyslO"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'List' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[39], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mkeyword_extractor\u001b[39m(bert:\u001b[39mstr\u001b[39m, documents:List[\u001b[39mstr\u001b[39m]):\n\u001b[0;32m      2\u001b[0m   model \u001b[39m=\u001b[39m BertModel\u001b[39m.\u001b[39mfrom_pretrained(bert)\n\u001b[0;32m      3\u001b[0m   model \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mcuda()\n",
            "\u001b[1;31mNameError\u001b[0m: name 'List' is not defined"
          ]
        }
      ],
      "source": [
        "def keyword_extractor(bert:str, documents:List[str]):\n",
        "  model = BertModel.from_pretrained(bert)\n",
        "  model = model.cuda()\n",
        "  kw_model = KeyBERT(model)\n",
        "  keywords = kw_model.extract_keywords(documents, keyphrase_ngram_range=(1, 1), stop_words=None, top_n=20)\n",
        "  return keywords\n",
        "# model_100langs = BertModel.from_pretrained('sentence-transformers/xlm-r-100langs-bert-base-nli-stsb-mean-tokens')\n",
        "# kw_model_100langs = KeyBERT(model_100langs)\n",
        "# keywords_100langs = kw_model_100langs.extract_keywords(text, keyphrase_ngram_range=(1, 1), stop_words=None, top_n=20)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# gpu 사용법\n",
        "# https://github.com/MaartenGr/KeyBERT/issues/108\n",
        "model = SentenceTransformer(\n",
        "    \"<hf_model_name>\",\n",
        "    device=\"cuda:0\"\n",
        ")\n",
        "print(\"DEVICE\", model.device)\n",
        "hf_model = KeyBERT(model)\n",
        "\n",
        "# https://www.kaggle.com/code/accountstatus/shopee-competition-using-bert-model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "CXJC5qTf6j3n"
      },
      "outputs": [],
      "source": [
        "# print(os.getcwd())\n",
        "# base_path = \"/content/drive/MyDrive/쳇, 6pt: 비스킷(biskuit)/dataset/content/\"\n",
        "base_path = '../../../data/content/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "64ezQHBbiJ9K"
      },
      "outputs": [],
      "source": [
        "def extract_keyword(base_path:str):\n",
        "  content_dir_list = os.scandir(base_path)\n",
        "  documents = []\n",
        "  for content_dir in content_dir_list:\n",
        "      if not content_dir.is_dir(): continue\n",
        "      content_list = os.scandir(content_dir)\n",
        "      for content in content_list:\n",
        "          if not content.is_file(): continue\n",
        "          file = open(content.path, \"r\")\n",
        "          if len(text.split('\\n')) > 50:\n",
        "            summary = summarize(text)\n",
        "          else:\n",
        "            summary = text\n",
        "          # nouns = noun_extractor(text)\n",
        "          nouns = noun_extractor(summary)\n",
        "          text = ' '.join(nouns)\n",
        "          documents.append(text)\n",
        "  # print(text)\n",
        "  keyword_extractor('skt/kobert-base-v1', documents)\n",
        "  # keyword_extractor('paraphrase-multilingual-MiniLM-L12-v2', documents)   # multilingual!\n",
        "  # keyword_extractor('paraphrase-multilingual-mpnet-base-v2', documents)   # 시간 더 오래걸리고 결과 더 조음!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "faster_keywords = extract_keyword(base_path)\n",
        "faster_counter = Counter(faster_keywords)\n",
        "print(faster_counter.most_common(100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "bgA6BUyFa3qR"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2616efa599054b6cb83af88f3bce9163",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[(None, 3224)]\n"
          ]
        }
      ],
      "source": [
        "# file = open(data_path + \"2022-09-22_29CM_예약하기 서비스 개발기 (1)\" + \".txt\", \"r\")\n",
        "content_dir_list = os.scandir(base_path)\n",
        "keywords = [] \n",
        "for content_dir in tqdm(content_dir_list):\n",
        "  if not content_dir.is_dir(): continue\n",
        "  content_list = os.scandir(content_dir)\n",
        "  for content in content_list:\n",
        "    if not content.is_file(): continue\n",
        "    file = open(content.path, \"r\")\n",
        "    keywords.append(extract_keyword(file))\n",
        "counter = Counter(keywords)\n",
        "print(counter.most_common(100))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
